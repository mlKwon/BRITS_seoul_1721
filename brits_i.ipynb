{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c7d3a24a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "importing Jupyter notebook from utils.ipynb\n",
      "importing Jupyter notebook from data_loader.ipynb\n",
      "importing Jupyter notebook from rits_i.ipynb\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "\n",
    "from torch.autograd import Variable\n",
    "from torch.nn.parameter import Parameter\n",
    "\n",
    "import import_ipynb\n",
    "import math\n",
    "import utils\n",
    "import argparse\n",
    "import data_loader\n",
    "import numpy as np\n",
    "import rits_i\n",
    "\n",
    "from ipdb import set_trace\n",
    "from sklearn import metrics\n",
    "\n",
    "\n",
    "class Model(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Model, self).__init__()\n",
    "        self.build()\n",
    "\n",
    "    def build(self):\n",
    "        self.rits_f = rits_i.Model()\n",
    "        self.rits_b = rits_i.Model()\n",
    "\n",
    "    def forward(self, data):\n",
    "        ret_f = self.rits_f(data, 'forward')\n",
    "        ret_b = self.reverse(self.rits_b(data, 'backward'))\n",
    "\n",
    "        ret = self.merge_ret(ret_f, ret_b)\n",
    "\n",
    "        return ret\n",
    "\n",
    "    def merge_ret(self, ret_f, ret_b):\n",
    "        loss_f = ret_f['loss']\n",
    "        loss_b = ret_b['loss']\n",
    "        loss_c = self.get_consistency_loss(ret_f['imputations'], ret_b['imputations'])\n",
    "\n",
    "        loss = loss_f + loss_b + loss_c\n",
    "\n",
    "        imputations = (ret_f['imputations'] + ret_b['imputations']) / 2\n",
    "\n",
    "        ret_f['loss'] = loss\n",
    "        ret_f['imputations'] = imputations\n",
    "\n",
    "        return ret_f\n",
    "\n",
    "    def get_consistency_loss(self, pred_f, pred_b):\n",
    "        loss = torch.pow(pred_f - pred_b, 2.0).mean()\n",
    "        return loss\n",
    "\n",
    "    def reverse(self, ret):\n",
    "        def reverse_tensor(tensor_):\n",
    "            if tensor_.dim() <= 1:\n",
    "                return tensor_\n",
    "            indices = range(tensor_.size()[1])[::-1]\n",
    "            indices = Variable(torch.LongTensor(indices), requires_grad = False)\n",
    "\n",
    "            if torch.cuda.is_available():\n",
    "                indices = indices.cuda()\n",
    "\n",
    "            return tensor_.index_select(1, indices)\n",
    "\n",
    "        for key in ret:\n",
    "            ret[key] = reverse_tensor(ret[key])\n",
    "\n",
    "        return ret\n",
    "\n",
    "    def run_on_batch(self, data, optimizer):\n",
    "        ret = self(data)\n",
    "\n",
    "        if optimizer is not None:\n",
    "            optimizer.zero_grad()\n",
    "            ret['loss'].backward()\n",
    "            optimizer.step()\n",
    "\n",
    "        return ret"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
