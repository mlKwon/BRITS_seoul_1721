{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "18f50ebf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "importing Jupyter notebook from utils.ipynb\n",
      "importing Jupyter notebook from data_loader.ipynb\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "\n",
    "from torch.autograd import Variable\n",
    "from torch.nn.parameter import Parameter\n",
    "\n",
    "import import_ipynb\n",
    "import math\n",
    "import utils\n",
    "import argparse\n",
    "import data_loader\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from ipdb import set_trace\n",
    "from sklearn import metrics\n",
    "\n",
    "\n",
    "class FeatureRegression(nn.Module):\n",
    "    def __init__(self, input_size):\n",
    "        super(FeatureRegression, self).__init__()\n",
    "        self.build(input_size)\n",
    "        \n",
    "\n",
    "    def build(self, input_size):\n",
    "        self.W = Parameter(torch.Tensor(input_size, input_size))\n",
    "        self.b = Parameter(torch.Tensor(input_size))\n",
    "\n",
    "        m = torch.ones(input_size, input_size) - torch.eye(input_size, input_size)\n",
    "        self.register_buffer('m', m)\n",
    "        \n",
    "        self.reset_parameters()\n",
    "\n",
    "    def reset_parameters(self):\n",
    "        dw = pd.read_csv(\"E:/데이터모음/대기오염/preprocess/latlong_distance.csv\") # this data is for using IDW. I already calulate the distance based on latitude and logitude of monitoing sites.\n",
    "        self.W.data=torch.from_numpy(dw.values).float()\n",
    "        stdv = 1. / math.sqrt(self.W.size(0))\n",
    "#         self.W.data.uniform_(-stdv, stdv)\n",
    "        if self.b is not None:\n",
    "            self.b.data.uniform_(-stdv, stdv)\n",
    "\n",
    "    def forward(self, x):\n",
    "        z_h = F.linear(x, self.W * Variable(self.m), self.b) # W * self.m -> considering feature correlate\n",
    "        return z_h\n",
    "\n",
    "class TemporalDecay(nn.Module):\n",
    "    def __init__(self, input_size, output_size, diag = False):\n",
    "        super(TemporalDecay, self).__init__()\n",
    "        self.input_size = input_size\n",
    "        self.output_size = output_size\n",
    "        self.diag = diag\n",
    "\n",
    "        self.build(self.input_size, self.output_size)\n",
    "\n",
    "    def build(self, input_size, output_size):\n",
    "        self.W = Parameter(torch.Tensor(self.output_size, self.input_size))\n",
    "        self.b = Parameter(torch.Tensor(self.output_size))\n",
    "        \n",
    "        if self.diag == True:\n",
    "            assert(self.input_size == self.output_size)\n",
    "            m = torch.eye(self.input_size, self.input_size)\n",
    "            self.register_buffer('m', m)\n",
    "\n",
    "        self.reset_parameters()\n",
    "\n",
    "    def reset_parameters(self):\n",
    "        stdv = 1. / math.sqrt(self.W.size(0))\n",
    "        self.W.data.uniform_(-stdv, stdv)\n",
    "        if self.b is not None:\n",
    "            self.b.data.uniform_(-stdv, stdv)\n",
    "\n",
    "    def forward(self, d):\n",
    "        if self.diag == True:\n",
    "            gamma = F.relu(F.linear(d, self.W * Variable(self.m), self.b))\n",
    "        else:\n",
    "            gamma = F.relu(F.linear(d, self.W, self.b))\n",
    "        gamma = torch.exp(-gamma)\n",
    "        return gamma\n",
    "\n",
    "class Model(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Model, self).__init__()\n",
    "        self.build()\n",
    "\n",
    "    def build(self):\n",
    "        self.rnn_hid_size = 64\n",
    "        self.input_size = 25\n",
    "        self.rnn_cell = nn.RNNCell(self.input_size * 2, self.rnn_hid_size)\n",
    "\n",
    "        self.temp_decay_h = TemporalDecay(input_size = self.input_size, output_size = self.rnn_hid_size, diag = False) # input_size : variable number?\n",
    "        self.temp_decay_x = TemporalDecay(input_size = self.input_size, output_size = 25, diag = True)\n",
    "        self.hist_reg = nn.Linear(self.rnn_hid_size,25)\n",
    "        self.feat_reg = FeatureRegression(25)\n",
    "\n",
    "        self.weight_combine = nn.Linear(self.input_size * 2, 25)\n",
    "\n",
    "        self.dropout = nn.Dropout(p = 0.25)\n",
    "        self.out = nn.Linear(self.rnn_hid_size, 1)\n",
    "\n",
    "    def forward(self, data, direct, seq_len):\n",
    "        # Original sequence with 24 time steps\n",
    "        self.seq_len = seq_len\n",
    "        values = data[direct]['values']\n",
    "        masks = data[direct]['masks']\n",
    "        deltas = data[direct]['deltas']\n",
    "\n",
    "        evals = data[direct]['evals']\n",
    "        eval_masks = data[direct]['eval_masks']\n",
    "\n",
    "        h = Variable(torch.zeros((values.size()[0], self.rnn_hid_size)))\n",
    "        c = Variable(torch.zeros((values.size()[0], self.rnn_hid_size)))\n",
    "\n",
    "        if torch.cuda.is_available():\n",
    "            h, c = h.cuda(), c.cuda()\n",
    "\n",
    "        loss = 0.0\n",
    "\n",
    "        imputations = []\n",
    "        \n",
    "        for t in range(self.seq_len):\n",
    "            x = values[:, t, :]  # (batch_size, seq_len, input_size=output) : (batch_size,120,25) -> (batch_size,25)\n",
    "            m = masks[:, t, :]   # (batch_size, length of time, length of features)\n",
    "            d = deltas[:, t, :]\n",
    "\n",
    "            gamma_h = self.temp_decay_h(d)\n",
    "            gamma_x = self.temp_decay_x(d)\n",
    "\n",
    "#             h = h * gamma_h\n",
    "            x_h = self.hist_reg(h)\n",
    "            loss += torch.sum(torch.abs(x - x_h) * m) / (torch.sum(m) + 1e-5)\n",
    "\n",
    "            x_c =  m * x +  (1 - m) * x_h\n",
    "            z_h = self.feat_reg(x_c) # feature-based estimation\n",
    "            loss += torch.sum(torch.abs(x - z_h) * m) / (torch.sum(m) + 1e-5)\n",
    "            \n",
    "            beta = self.weight_combine(torch.cat([gamma_x, m], dim = 1))\n",
    "            c_h = beta * z_h + (1 - beta) * x_h\n",
    "            loss += torch.sum(torch.abs(x - c_h) * m) / (torch.sum(m) + 1e-5)\n",
    "            c_c = m * x + (1 - m) * c_h\n",
    "            h = h * gamma_h\n",
    "            \n",
    "            inputs = torch.cat([c_c, m], dim = 1)\n",
    "            \n",
    "            h = self.rnn_cell(inputs, h)\n",
    "            imputations.append(c_c.unsqueeze(dim = 1))\n",
    "\n",
    "        imputations = torch.cat(imputations, dim = 1)\n",
    "\n",
    "        return {'loss': loss/self.seq_len, 'imputations': imputations, 'evals': evals, 'eval_masks': eval_masks}\n",
    "\n",
    "    def run_on_batch(self, data, optimizer, seq_len):\n",
    "        ret = self(data, direct = 'forward',seq_len=seq_len)\n",
    "        if optimizer is not None:\n",
    "            optimizer.zero_grad()\n",
    "            ret['loss'].backward()\n",
    "            optimizer.step()\n",
    "\n",
    "        return ret"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
