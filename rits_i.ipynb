{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72971ded",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "\n",
    "from torch.autograd import Variable\n",
    "from torch.nn.parameter import Parameter\n",
    "\n",
    "import import_ipynb\n",
    "import math\n",
    "import utils\n",
    "import argparse\n",
    "import data_loader\n",
    "import numpy as np\n",
    "\n",
    "from ipdb import set_trace\n",
    "from sklearn import metrics\n",
    "\n",
    "\n",
    "class TemporalDecay(nn.Module):\n",
    "    def __init__(self, input_size):\n",
    "        super(TemporalDecay, self).__init__()\n",
    "        self.rnn_hid_size = 64\n",
    "        self.build(input_size)\n",
    "\n",
    "    def build(self, input_size):\n",
    "        self.W = Parameter(torch.Tensor(self.rnn_hid_size, input_size))\n",
    "        self.b = Parameter(torch.Tensor(self.rnn_hid_size))\n",
    "        self.reset_parameters()\n",
    "\n",
    "    def reset_parameters(self):\n",
    "        stdv = 1. / math.sqrt(self.W.size(0))\n",
    "        self.W.data.uniform_(-stdv, stdv)\n",
    "        if self.b is not None:\n",
    "            self.b.data.uniform_(-stdv, stdv)\n",
    "\n",
    "    def forward(self, d):\n",
    "        gamma = F.relu(F.linear(d, self.W, self.b))\n",
    "        gamma = torch.exp(-gamma)\n",
    "        return gamma\n",
    "\n",
    "class Model(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Model, self).__init__()\n",
    "        self.rnn_hid_size = 64\n",
    "        self.seq_len = 120\n",
    "        self.build()\n",
    "\n",
    "    def build(self):\n",
    "        self.rnn_cell = nn.LSTMCell(25 * 2, self.rnn_hid_size)\n",
    "\n",
    "        self.regression = nn.Linear(self.rnn_hid_size, 25)\n",
    "        self.temp_decay = TemporalDecay(input_size = 25)\n",
    "\n",
    "        self.out = nn.Linear(self.rnn_hid_size, 1)\n",
    "\n",
    "    def forward(self, data, direct):\n",
    "        # Original sequence with 24 time steps\n",
    "        values = data[direct]['values']\n",
    "        masks = data[direct]['masks']\n",
    "        deltas = data[direct]['deltas']\n",
    "\n",
    "        evals = data[direct]['evals']\n",
    "        eval_masks = data[direct]['eval_masks']\n",
    "\n",
    "        h = Variable(torch.zeros((values.size()[0], self.rnn_hid_size)))\n",
    "        c = Variable(torch.zeros((values.size()[0], self.rnn_hid_size)))\n",
    "\n",
    "        if torch.cuda.is_available():\n",
    "            h, c = h.cuda(), c.cuda()\n",
    "\n",
    "        x_loss = 0.0\n",
    "\n",
    "        imputations = []\n",
    "\n",
    "        for t in range(self.seq_len):\n",
    "            x = values[:, t, :]\n",
    "            m = masks[:, t, :]\n",
    "            d = deltas[:, t, :]\n",
    "\n",
    "            gamma = self.temp_decay(d)\n",
    "            h = h * gamma\n",
    "            x_h = self.regression(h)\n",
    "\n",
    "            x_c =  m * x +  (1 - m) * x_h\n",
    "\n",
    "            x_loss += torch.sum(torch.abs(x - x_h) * m) / (torch.sum(m) + 1e-5)\n",
    "\n",
    "            inputs = torch.cat([x_c, m], dim = 1)\n",
    "\n",
    "            h, c = self.rnn_cell(inputs, (h, c))\n",
    "\n",
    "            imputations.append(x_c.unsqueeze(dim = 1))\n",
    "\n",
    "        imputations = torch.cat(imputations, dim = 1)\n",
    "\n",
    "        return {'loss': x_loss / self.seq_len,\\\n",
    "                'imputations': imputations,\\\n",
    "                'evals': evals, 'eval_masks': eval_masks}\n",
    "\n",
    "    def run_on_batch(self, data, optimizer):\n",
    "        ret = self(data, direct = 'forward')\n",
    "\n",
    "        if optimizer is not None:\n",
    "            optimizer.zero_grad()\n",
    "            ret['loss'].backward()\n",
    "            optimizer.step()\n",
    "\n",
    "        return ret"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
